[
    {
    "id":1,
    "tags": [ "hackathon" , "social-good" , "mobile-app" , "team" , "award" ],
    "languages_used": [ "C#" ],
    "tools_used": [ "Unity", "IBM-Watson" ],
    "date": "20171118",
    "title": "bridgED",
    "project_description": "Hack Western 2017. Real-time image analysis and language translation of everyday objects and signs. Our app is designed to fit two goals. 1: With integrated wiki access, allow users to learn about the objects around them. 2: Combining AR, our app allows foreigners to quickly understand what objects are, and refer to them with ease- especially helpful for ambiguous/culturally specific items, and road signs.",
    "work_description": "Coming up with the idea, I helped lead the team towards developing an application that would accomplish the goal of helping newly immigrated Canadians. For the app, I worked primarily on the AR portion of the application, utilizing libraries and putting together a simple Unity app.",
    "learn_description": "While I had worked with Unity in the past, I never worked on getting the very foundations done. Besides having to learn how to integrate new libraries, I feel like it was at this Hackathon that I really concreted what was necessary to win. Our work process was messy at places, as we had to figure things out on the fly. However, I think I have a better idea as to what a good workflow would be for the future. I was very fortunate to have a diligent team as well!",
    "images": [ "bridgED1.png", "bridgED2.png" ],
    "link_git": "",
    "link_generic": "https://devpost.com/software/what-s-it",
    "awards":[ "Best Use of IBM Watson Visual Recognition API" , "Best Hack for Empowering Diversity through Design and Technology" ]
    },
    {
    "id":2,
    "tags": [ "hackathon" , "front-end" , "website" , "team", "award" ],
    "languages_used": [ "JavaScript", "html" , "php" ],
    "tools_used": [ "phpMyAdmin" ],
    "date": "20170917",
    "title": "Coincise",
    "project_description": "Hack the North 2017. A cryptocurrency portfolio management tool. Using deep learning algorithms, our machine learning bot analyzes historical data in order to predict whether or not a coin will rise or fall in the short run, providing a basic recommendation for the user as to whether they should buy or sell. The goal is to provide an extension to Coinbase's existing services and provide better financial management tools for users to earn.",
    "work_description": "With a teammate experienced in machine learning, I took the role of team lead and brainstormed it's best application. Thinking from the perspective of Coinbase, I laid out features we'd need and the packaging to make it appealing for an award. I did the front-end management, writing and designing our site.",
    "learn_description": "This was my first serious hackathon- while I did one before, I came into this with the goal of winning. I've only done minimal web-dev in the past. Although our demo site wasn't too complicated, this was my first taste of delving into more complicated libraries like chart-generators and handling asynchronous data calls to other servers.",
    "images": [ "coincise1.jpg" , "coincise2.jpg" ],
    "link_git":"",
    "link_generic":"https://devpost.com/software/coincise",
    "awards":[ "Coinbase Sponsor Award" ]
    },
    {
    "id":3,
    "tags": [ "hackathon" , "back-end" , "social-good", "website" , "team", "award" ],
    "languages_used": [ "JavaScript" ],
    "tools_used": [ "stdlib" , "REST" ],
    "date": "20180205",
    "title": "Search and Protect",
    "project_description": "QHacks 2018. A mental health monitoring tool usable for suicide prevention groups. Using sentiment analysis, we score Twitter user's negativity and overall tendency to self-harm. The site's management group gets notified of this. Then, using our personality profiling and key-word summaries, the administrator will be able to have a more guided conversation with the user. Using our built-in extension, they can directly DM the user through the group's twitter account and start a conversation. The tool additionally has an automated contact for high-risk individuals, encouraging them to seek help.",
    "work_description": "Dividing up tasks, our more experienced member took on the role of designing our React front-end. I worked closely with him throughout the project as I designed the back-end, feeding him the data to display. This included incorporating multiple APIs, processing and passing data between them. These functions were hosted on stdlib, one of the hackathon's sponsors. Our other two members supported us, searching up documentation, coding portions of what we needed, and helping us setup the infrastructure.",
    "learn_description": "This gave me a chance to really work seriously with JavaScript and use it for more serious programming. I had to learn how to use large REST API libraries on my own in a short period of time- including Twitter's and IBM Watson's. I also had to learn how to deal with more difficult team members, which was a first for me.",
    "images": [ "searchandprotect1.jpg" , "searchandprotect2.jpg" ],
    "link_git":"https://github.com/RunEMC/SearchAndPro.tech",
    "link_generic":"https://devpost.com/software/qhacks-2018",
    "awards":[ "Top-5 Finalist" ]
    },
    {
    "id":4,
    "tags": [ "website" , "front-end", "solo" ],
    "languages_used": [ "JavaScript" , "html" , "php" ],
    "tools_used": [ "Online Tutorials" ],
    "date": "20160924",
    "title": "Personal Site V1",
    "project_description": "The first version of my personal website. This was my first serious venture into redesign, where I worked closely with the HTML and CSS. The site features basic details, including a projects session, a resume section, a personal summary, and contact section. The webform would route mail directly to my personal account. This was me getting my feet wet.",
    "work_description": "I had to learn how to do everything from scratch. How and where to host a site, the fundamentals of HTML/CSS/JS, the workflow, the pain of designing using CSS properties. Ultimately the thing that took me the longest with this was getting used to html/CSS design and getting my layouts the way I envision.",
    "learn_description": "A lot about patience learning on your own. Basic web-design practices otherwise.",
    "images": [ "personalsite1.png" , "personalsite2.png" ],
    "link_git":"https://github.com/RunEMC/SearchAndPro.tech",
    "link_generic":"https://devpost.com/software/qhacks-2018",
    "awards":[ ]
    },
    {
    "id":5,
    "tags": [ "mobile-application" , "front-end", "co-op" , "game" ],
    "languages_used": [ "C#" ],
    "tools_used": [ "Unity" ],
    "date": "20160724",
    "title": "Gamestudio Trillionaire",
    "project_description": "A satirical clicker game on running your own game studio. Packaged in quirky manner with jokes regarding common tropes of the industry and overall fun aesthetic. Collect absurd amounts of money, beyond 10^24 (I forget our specific cap). Designed in Unity, our multi-platform game was released on Kongregate, iOS and Android. On Android, it accumulated over 100k downloads and had an average rating of 4.3! Unfortunately, the company has since chosen to remove many of their lesser titles, and Game Studio Trillionaire is no longer available. I do however, have an APK of the game saved (linked below).",
    "work_description": "One of the most personally ambitious projects I got to work on at Clipwire Games- in the sense that I personally lead most of the creative process. It was intended to simply be a test game for our new tools and workflow, but I enjoyed working on it and asked to continue adding more features. Pitching these ideas to our CEO, I continued to develop and work with our art designer for new assets. I did everything else- from modifying our math calculations, changing the user data we store, wireframing features, designing new menus, coding UI functionality, animating events, writing the jokes, balancing the game, debugging, putting it up on the app store. Nearly everything!",
    "learn_description": "This was a big responsibility for me, and I got to take on more than I usually do. Before this, I normally would focus on adding UI, basic front-end based features, and debugging. Our company was small, and the others were generally busy, so I had to learn much on my own. I think it was a this point that I could confidently say, that I had experienced the entire development cycle of an application, first-hand. ",
    "images": [ "gamestudio1.jpg" , "gamestudio2.jpg" ],
    "link_git":"",
    "link_generic":"",
    "awards":[ ]
    },
    {
    "id":6,
    "tags": [ "automation" , "environment", "co-op" , "solo" ],
    "languages_used": [ "Bash" , "Java" ],
    "tools_used": [ "Unix" , "Rundeck" , "Calypso" ],
    "date": "20180320",
    "title": "Continuous Delivery Automation",
    "project_description": "The automation of tasks required to get a build from dev to PROD. This project involved connecting various tasks and scripts our QA/Release Management team would normally do manually, and allow it to be easily triggered and done autonomously via an UI (Rundeck). I did not take any photos of the project itself, nor kept source code due to company policy (so no links or pics).",
    "work_description": "I worked solo on this project, and was tasked to automate our typical workflow for 2 applications. It was my job to figure out what needed to be done, and how to do it. This required a lot of planning, with small specifics regarding environment management to consider. I wanted the end product to require as little maintenance as possible, while covering common fail cases. This included running out of environment storage or RAM, builds or deployments failing, cookies expiring, and changes in naming conventions. For example, to save storage, I changed our setup to keep a copy of builds on one drive, before SSHing into our other environments. Since we often had to deploy different versions to environments, I made the system do so in parallel to reduce time.\\n I wireframed and flowcharted my plan and presented my ideas before moving forward. Ignoring smaller management steps and error checking, the end product worked as follows: Dev creates build, triggering job -> Build and other versions get installed on QA environments as required -> Scripts login to web interface to deploy required files -> Connection with our application triggers our QA test -> Results are reconciled into a report -> Report gets emailed directly to the team. And yes, I had a few other email points to alert the team on our build's progress!  In the end, I wrote about 30-40 Bash scripts and a couple of Java scripts to interface with our application! While the end product was flexible enough to be adapted to deploying to PAT and PROD, we never got there as we were waiting business approvals to do so.",
    "learn_description": "As I worked on the project, I would often realize minor details that were important to be programmed around. For example. figuring out how to deploy our files to our web server was a bit convoluted, as corporate policy required us to go through it. In the end, I ended up using simple curl commands to login, cache cookies, and upload our required files. All in all, this project simply required me to learn a lot on my own. While I could, and sometimes did, reach out to coworkers, they were busy working on features instead, and weren't explicitly familiar with what I was doing. My investigative skills and patience were really pushed!",
    "images": [ "rundeck1.png" , "rundeck2.png" ],
    "link_git":"",
    "link_generic":"",
    "awards":[ ]
    },
    {
    "id":7,
    "tags": [ "automation" , "web-scrapping", "solo" ],
    "languages_used": [ "Bash" ],
    "tools_used": [ "Unix" , "curl" ],
    "date": "20180604",
    "title": "Sona Posting Page Checker",
    "project_description": "A script that logins to a site, stores the cookie, and scraps one of their pages for new postings. If new postings are found, an email notification is sent to a mailing list. I made this script since postings would randomly, infrequently appear, and I found myself (and my colleagues) checking the page multiple times a day.",
    "work_description":  "Like all my scripts, I tried to design a script that's easy for users to modify and would require little to no maintenance. Variables are well defined; user data is separated off to other files. The script is fairly basic, though I found issues along the way. It logs in, grabs a cookie value, travels to the posting page, scraps data, and sends email alerts along the way. However, there was a bunch of unknowns that made the process tough. First, it was an ASP.NET application. I wasn't familiar with it, but they had things like validation hashes and obscure forwarding pages, which made me do a lot of trial and error to debug. Additionally, I learned about HTML URL encoding, which unbeknownst to me, attributed to some of the errors. My machine and the server I hosted the script on turned out to have different curl versions too! In the end, I spent a lot of time playing with different data/header/formatting combinations.",
    "learn_description": "I think in the future, I'll put a little more effort into searching the net for references. While the specifics made it hard to find, if I found out about the encoding difference, that would have sped things up. I also spent along time fretting over how ASP.NET might make curl requests have different requirements. In the future, I think I should have tried coding it earlier instead of trying different options to make it work without it. This way I would have affirmed 100% that it wasn't an issue, instead of it being an overhanging possibility.",
    "images": [ "sona.png" ],
    "link_git":"",
    "link_generic":"",
    "awards":[ ]
    },
    {
    "id":8,
    "tags": [ "machine-learning", "data" , "web-scrapping", "solo" ],
    "languages_used": [ "Python" ],
    "tools_used": [ "TensorFlow" , "sqlite", "TD Da Vinci" ],
    "date": "20180918",
    "title": "CouponIT",
    "project_description": "The idea is to allow retailers to effectively price discriminate their customers and maximize profits by providing the optimal discount rate to convert a specific individual into a user. In order to determine this rate, their transactional data and demographics are analyzed through the use of TD Da Vinci, which provides the data set. By determining the amount, they spend between the company and it’s competitors, a priority score is generated. This number, as well as demographic data, is fed into a ML model, which will determine a function using these variables, giving us a way to accurately determine an effective coupon rate for each individual. Data is then recollected post coupon distribution, where the change in score will signify the success of the proposed rate- thus training the model for future iterations.",
    "work_description": "This project represented the first time I seriously used Python, my first attempt in delving into proper data analysis, and my first-time exploring ML algorithms.  I had to learn a lot from tutorials, and it was hours after I first decided on the idea until I figured out how I would be applying ML to the data set and how I would train it. All in all, while the number of lines of code wasn’t large, I learned a lot, and ultimately ended up doing most of the work within one long 12-hour time frame!",
    "learn_description": "Besides getting more insight on the topics above, in general it was a great way to learn about some of the quirks of the language. For example, I ran into a lot of trouble converting values between Python, my SQLite database, URL requests, and JSON in general. Figuring out how to store floats and complex non-string escaped text and ensure they would be converted between formats was troubling at times, but I figured it out!",
    "images": [ "couponit.png" ],
    "link_git":"https://github.com/Roland-Li/coupon-analysis",
    "link_generic":"https://devpost.com/software/ml-couponing-for-maximizing-user-conversion",
    "awards":[ ]
    }    
]

